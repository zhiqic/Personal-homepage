<!DOCTYPE HTML>
<html lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-7580334-2');
  </script>

  <title>Zhi-Qi Cheng</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  
  <meta name="author" content="Zhi-Qi Cheng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="style/stylesheet.css">
  <link rel="stylesheet" type="text/css" href="style/orig.css" media="all" />
</head>

<body class="blue light">
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:10px;">
      <tbody>
        <tr style="padding:0px">
        <td style="padding:0px">

        <ul class="menu">
            <li><a href="index.html">Home</a></li>
            <li class="active"><a href="publication.html">Publication</a></li>
            <li><a href="teaching.html">Teaching</a></li>
            <li><a href="projects.html">Projects</a></li>     
            <li><a href="talks.html">Engagements</a></li>                
            <li><a href="miscellaneous.html">Miscellaneous</a></li>             
        </ul>

        
        <hr>
        <h4>For a comprehensive list of my publications, please visit my <a href="https://scholar.google.com/citations?user=uB2He2UAAAAJ&hl=en" target="_blank">Google Scholar profile</a>.</h4>
          
        For additional information and access to the code related to publication, please visit my GitHub repositories at <a href="https://github.com/zhiqic?tab=repositories" target="_blank">https://github.com/zhiqic?tab=repositories</a>.
        <hr> 
        
       <h3>IV: Beyond LLM: Multimodal Knowledge-Driven Comprehension</h3>
       <h4>Publications in Conference Proceedings and Journals:</h4>
       <ul>
        <li>
          <strong>ChartReader: A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules</strong><br>
          [<a href="https://arxiv.org/pdf/2304.02173.pdf">pdf</a>][<a href="https://github.com/zhiqic/ChartReader">code</a>]
          <u>Zhi-Qi Cheng</u>, Qi Dai, Siyao Li, Jingdong Sun, Teruko Mitamura, Alexander G Hauptmann<br>
          <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023</em>
        </li>
        <li>
          <strong>Gsrformer: Grounded situation recognition transformer with alternate semantic attention refinement</strong><br>
          <u>Zhi-Qi Cheng</u>, Qi Dai, Siyao Li, Teruko Mitamura, Alexander Hauptmann<br>
          <em>Proceedings of the 30th ACM International Conference on Multimedia (ACM MM), 2022</em> (<font color='red'>Oral Presentation</font>)
        </li>
        <li>
          <strong>WordArt Designer: User-Driven Artistic Typography Synthesis using Large Language Models</strong><br>
          Jun-Yan He, <u>Zhi-Qi Cheng^</u>, Chenyang Li, Jingdong Sun, Wangmeng Xiang, Xianhui Lin, Xiaoyang Kang, Zengke Jin, Yusen Hu, Bin Luo, and others<br>
          <em>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023</em>
        </li>
        <li>
          <strong>Implicit temporal modeling with learnable alignment for video recognition</strong><br>
          Shuyuan Tu, Qi Dai, Zuxuan Wu, <u>Zhi-Qi Cheng</u>, Han Hu, Yu-Gang Jiang<br>
          <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2023</em> (<font color='red'>Oral Presentation</font>)
        </li>
      </ul>
      <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>
      <hr>
      <h4>Publications in Refereed Workshops:</h4>
      <ul>
        <li>
          <strong>WordArt Designer API: User-Driven Artistic Typography Synthesis using Large Language Models</strong><br>
          Jun-Yan He, <u>Zhi-Qi Cheng^</u>, Chenyang Li, Jingdong Sun, Wangmeng Xiang, Xianhui Lin, Xiaoyang Kang, Zengke Jin, Yusen Hu, Bin Luo, and others<br>
          <em>NeurIPS Workshop on Machine Learning for Creativity and Design, 2023</em>
        </li>
        <li>
          <strong>Towards Calibrated Robust Fine-Tuning of Vision-Language Models</strong><br>
          Changdae Oh, Mijoo Kim, Hyesu Lim, Junhyeok Park, Euiseog Jeong, <u>Zhi-Qi Cheng^</u>, Kyungwoo Song^<br>
          <em>NeurIPS Workshop on Distribution Shifts, 2023</em>
        </li>
        <li>
          <strong>Perceiving physical equation by observing visual scenarios</strong><br>
          Siyu Huang†, <u>Zhi-Qi Cheng†</u>, Xi Li, Xiao Wu, Zhongfei Zhang, Alexander Hauptmann<br>
          <em>NeurIPS Workshop on Modeling the Physical World, 2018</em>
        </li>
        </ul>
        <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>
        <h4>Other Articles and Preprints:</h4>
        <ul>
           <li>
            <strong>MotionEditor: Editing Video Motion via Content-Aware Diffusion</strong><br>
            Shuyuan Tu, Qi Dai, <u>Zhi-Qi Cheng</u>, Han Hu, Xintong Han, Zuxuan Wu, Yu-Gang Jiang<br>
            <em>arXiv preprint arXiv:2311.18830, 2023</em>
          </li>
          <li>
            <strong>ProS: Prompting-to-simulate Generalized knowledge for Universal Cross-Domain Retrieval</strong><br>
            Kaipeng Fang, Jingkuan Song, Lianli Gao, Pengpeng Zeng, <u>Zhi-Qi Cheng</u>, Xiyao Li, Heng Tao Shen<br>
            <em>arXiv preprint arXiv:2312.12478, 2023</em>
          </li>
          <li>
            <strong>Tracking with Human-Intent Reasoning</strong><br>
            Jiawen Zhu, <u>Zhi-Qi Cheng</u>, Jun-Yan He, Chenyang Li, Bin Luo, Huchuan Lu, Yifeng Geng, Xuansong Xie<br>
            <em>arXiv preprint arXiv:2312.17448, 2023</em>
          </li>
        </ul>
        <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>

        <hr>

        <h3>I: Human Rights & Public Safety: Multimedia Analysis & Assessment</h3>
        <h4>Publications in Conference Proceedings and Journals:</h4>
        <ul>
          <li>
            <strong>Learning spatial awareness to improve crowd counting</strong><br>
            <u>Zhi-Qi Cheng†</u>, Jun-Xiu Li†, Qi Dai, Xiao Wu, Alexander G Hauptmann<br>
            <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2019</em> 
            (<font color='red'>Oral Presentation; Acceptance rate: 4.3%</font>)
          </li>
          <li>
            <strong>Rethinking spatial invariance of convolutional networks for object counting</strong><br>
            <u>Zhi-Qi Cheng</u>, Qi Dai, Hong Li, Jingkuan Song, Xiao Wu, Alexander G Hauptmann<br>
            <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022</em> 
            (<font color='red'>Contributed to Pulitzer-winning Capitol Riot analysis by Washington Post 2022</font> )
          </li>
          <li>
            <strong>Improving the learning of multi-column convolutional neural network for crowd counting</strong><br>
            <u>Zhi-Qi Cheng†</u>, Jun-Xiu Li†, Qi Dai, Xiao Wu, Jun-Yan He, Alexander G Hauptmann<br>
            <em>Proceedings of the 27th ACM International Conference on Multimedia (ACM MM), 2019</em> 
            (<font color='red'>Oral Presentation</font>)
          </li>
          <li>
            <strong>PoSynDA: Multi-Hypothesis Pose Synthesis Domain Adaptation for Robust 3D Human Pose Estimation</strong><br>
            Hanbing Liu†, Jun-Yan He†^, <u>Zhi-Qi Cheng†^</u>, Wangmeng Xiang, Qize Yang, Wenhao Chai, Gaoang Wang, Xu Bao, Bin Luo, Yifeng Geng, et al.<br>
            <em>Proceedings of the 31st ACM International Conference on Multimedia (ACM MM), 2023</em>
          </li>
          <li>
            <strong>HDFormer: High-order Directed Transformer for 3D Human Pose Estimation</strong><br>
            Hanyuan Chen†, Jun-Yan He†, Wangmeng Xiang†, <u>Zhi-Qi Cheng†</u>, Wei Liu, Hanbing Liu, Bin Luo, Yifeng Geng, Xuansong Xie<br>
            <em>Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI), 2023</em>
          </li>
          <li>
            <strong>Crossnet: Boosting crowd counting with localization</strong><br>
            Ji Zhang, <u>Zhi-Qi Cheng</u>, Xiao Wu, Wei Li, Jian-Jun Qiao<br>
            <em>Proceedings of the 30th ACM International Conference on Multimedia (ACM MM), 2022</em>
          </li>
          <li>
            <strong>Stacked pooling for boosting scale invariance of crowd counting</strong><br>
            Siyu Huang, Xi Li, <u>Zhi-Qi Cheng</u>, Zhongfei Zhang, Alexander Hauptmann<br>
            <em>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020</em>
          </li>
          <li>
            <strong>DB-LSTM: Densely-connected Bi-directional LSTM for human action recognition</strong><br>
            Jun-Yan He, Xiao Wu, <u>Zhi-Qi Cheng</u>, Zhaoquan Yuan, Yu-Gang Jiang<br>
            <em>Neurocomputing, 2021</em>
          </li>
        </ul>
        <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>
        <h4>Other Articles and Preprints</h4>
        <ul>
          <li>
            <strong>Hypergraph transformer for skeleton-based action recognition</strong><br>
            Yuxuan Zhou, <u>Zhi-Qi Cheng^</u>, Chao Li, Yifeng Geng, Xuansong Xie, Margret Keuper<br>
            <em>arXiv preprint arXiv:2211.09590, 2022</em>
          </li>
          <li>
            <strong>Overcoming Topology Agnosticism: Enhancing Skeleton-Based Action Recognition through Redefined Skeletal Topology Awareness</strong><br>
            Yuxuan Zhou, <u>Zhi-Qi Cheng^</u>, Jun-Yan He, Bin Luo, Yifeng Geng, Xuansong Xie, Margret Keuper<br>
            <em>arXiv preprint arXiv:2305.11468, 2023</em>
          </li>
          <li>
            <strong>Refined Temporal Pyramidal Compression-and-Amplification Transformer for 3D Human Pose Estimation</strong><br>
            Hanbing Li†, Wangmeng Xiang†^, Jun-Yan He†, <u>Zhi-Qi Cheng†</u>, Bin Luo, Yifeng Geng, Xuansong Xie<br>
            <em>arXiv preprint arXiv:2309.01365, 2023</em>
          </li>
        </ul>
        <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>

        <hr>

        <h3>II: Visual E-commerce: Multimodal Retrieval & Recommendation</h3>
        <h4>Publications in Conference Proceedings and Journals:</h4>
        <ul>
          <li>
            <strong>Video2shop: Exact matching clothes in videos to online shopping images</strong><br>
            <u>Zhi-Qi Cheng</u>, Xiao Wu, Yang Liu, Xian-Sheng Hua<br>
            <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017</em> 
            (<font color='red'>Alibaba's Pailitao Project; 17M daily users; 30M users during 2017 Double 11 Festival</font>)
          </li>
          <li>
            <strong>Video eCommerce: Towards online video advertising</strong><br>
            <u>Zhi-Qi Cheng</u>, Yang Liu, Xiao Wu, Xian-Sheng Hua<br>
            <em>Proceedings of the 24th ACM International Conference on Multimedia (ACM MM), 2016</em> 
            (<font color='red'>Oral Presentation; Alibaba's Video eCommerce system</font>)
          </li>
          <li>
            <strong>Video eCommerce++: Toward large scale online video advertising</strong><br>
            <u>Zhi-Qi Cheng</u>, Xiao Wu, Yang Liu, Xian-Sheng Hua<br>
            <em>IEEE Transactions on Multimedia (IEEE TMM), 19(6), 2017</em> 
            (<font color='red'>Alibaba's Video eCommerce++ system; Recognized by China's Miaozi Program</font>)
          </li>
          <li>
            <strong>On the selection of anchors and targets for video hyperlinking</strong><br>
            <u>Zhi-Qi Cheng</u>, Hao Zhang, Xiao Wu, Chong-Wah Ngo<br>
            <em>Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval (ICMR), 2017: 287-293</em> 
            (<font color='red'>Special Oral Presentation</font>)
          </li>
          <li>
            <strong>Personalized clothing recommendation combining user social circle and fashion style consistency</strong><br>
            Guang-Lu Sun, <u>Zhi-Qi Cheng</u>, Xiao Wu, Qiang Peng<br>
            <em>Multimedia Tools and Applications, 77, 2018: 17731-17754</em>
          </li>
          <li>
            <strong>Multi-view image generation from a single-view</strong><br>
            Bo Zhao, Xiao Wu, <u>Zhi-Qi Cheng</u>, Hao Liu, Zequn Jie, Jiashi Feng<br>
            <em>Proceedings of the 26th ACM International Conference on Multimedia (ACM MM), 2018</em> 
            (<font color='red'>Oral Presentation</font>)
          </li>
          <li>
            <strong>Generating person images with appearance-aware pose stylizer</strong><br>
            Siyu Huang, Haoyi Xiong, <u>Zhi-Qi Cheng</u>, Qingzhong Wang, Xingran Zhou, Bihan Wen, Jun Huan, Dejing Dou, and others<br>
            <em>Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI), 2020</em>
          </li>
        </ul>
        <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>
        <h4>Publications in Refereed Workshops:</h4>
        <ul>
          <li>
            <strong>Vireo@ TRECVID 2017: Video-to-text, ad-hoc video search and video hyperlinking</strong><br>
            Phuong Anh Nguyen, Qing Li, <u>Zhi-Qi Cheng</u>, Yi-Jie Lu, Hao Zhang, Xiao Wu, Chong-Wah Ngo<br>
            <em>2017 TREC Video Retrieval Evaluation (TRECVID 2017), 2017</em> 
            (<font color='red'>1st Place in TRECVID LNK 2017 & 2nd Place in TRECVID AVS 2017</font>)
          </li>
          <li>
            <strong>Minimizing risk in video hyperlinking</strong><br>
            Chong-Wah Ngo, <u>Zhi-Qi Cheng</u>, Xiao Wu<br>
            <em>2017 TREC Video Retrieval Evaluation (TRECVID 2017), 2017</em> 
            (<font color='red'>Special Oral Presentation</font>)
          </li>
        </ul>
        <h4>Patents:</h4>
        <ul>
          <li>
            <strong>Determining recommended object</strong><br>
            <u>Zhi-Qi Cheng</u>, Yang Liu, Xian-Sheng Hua<br>
            <em>US Patent US10671851B2, 2020</em> (<font color='red'>Worldwide applications: 2017 - CN, TW; 2018 - WO, EP, US</font>)
          </li>
          <li>
            <strong>A kind of data handling system, method and device</strong><br>
            <u>Zhi-Qi Cheng</u>, Yang Liu, Xian-Sheng Hua<br>
            <em>CN Patent CN107,463,572 B, 2020</em>
          </li>
          <li>
            <strong>A kind of information-pushing method, apparatus, and system</strong><br>
            <u>Zhi-Qi Cheng</u>, Yang Liu, Xian-Sheng Hua<br>
            <em>CN Patent CN107,517,393 B, 2020</em>
          </li>
          <li>
            <strong>Information pushing method, device and system</strong><br>
            <u>Zhi-Qi Cheng</u>, Yang Liu, Xian-Sheng Hua<br>
            <em>CN Patent HK1248437A1, 2018</em> (<font color='red'>Worldwide applications: 2018-HK</font>)
          </li>
        </ul>

        <hr>

        <h3>III: Mobility21: Streaming Perception, Detection & Tracking</h3>
        <h4>Publications in Conference Proceedings and Journals:</h4>
        <ul>
          <li>
            <strong>DAMO-StreamNet: Optimizing Streaming Perception in Autonomous Driving</strong><br>
            Jun-Yan He†, <u>Zhi-Qi Cheng†^</u>, Chenyang Li†, Wangmeng Xiang, Binghui Chen, Bin Luo, Yifeng Geng, Xuansong Xie, and others<br>
            <em>Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI), 2023</em> 
            (<font color='red'>Recognized as the leading solution for Autonomous Driving Streaming Perception</font>)
          </li>
          <li>
            <strong>KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired True-Range Multilateration</strong><br>
            Xu Bao†, <u>Zhi-Qi Cheng†^</u>, Jun-Yan He†, Chenyang Li, Wangmeng Xiang, Jingdong Sun, Hanbing Liu, Wei Liu, Bin Luo, Yifeng Geng, and others<br>
            <em>Proceedings of the 31st ACM International Conference on Multimedia (ACM MM), 2023</em>
          </li>
          <li>
            <strong>Procontext: Exploring progressive context transformer for tracking</strong><br>
            Jin-Peng Lan†, <u>Zhi-Qi Cheng†</u>, Jun-Yan He†, Chenyang Li, Bin Luo, Xu Bao, Wangmeng Xiang, Yifeng Geng, Xuansong Xie, and others<br>
            <em>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023</em> 
            (<font color='red'>Oral Presentation</font>)
          </li>
          <li>
            <strong>Longshortnet: Exploring temporal and semantic features fusion in streaming perception</strong><br>
            Chenyang Li†, <u>Zhi-Qi Cheng†</u>, Jun-Yan He†, Pengyu Li, Bin Luo, Hanyuan Chen, Yifeng Geng, Jin-Peng Lan, Xuansong Xie, and others<br>
            <em>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2023</em>
          </li>
          <li>
            <strong>Learning to transfer: Generalizable attribute learning with multitask neural model search</strong><br>
            <u>Zhi-Qi Cheng</u>, Xiao Wu, Siyu Huang, Jun-Xiu Li, Alexander G Hauptmann, Qiang Peng<br>
            <em>Proceedings of the 26th ACM International Conference on Multimedia (ACM MM), 2018</em> 
            (<font color='red'>Oral Presentation</font>)
          </li>
          <li>
            <strong>Improving Anomaly Segmentation with Multi-Granularity Cross-Domain Alignment</strong><br>
            Ji Zhang, Xiao Wu^, <u>Zhi-Qi Cheng^</u>, Qi He, Wei Li<br>
            <em>Proceedings of the 31st ACM International Conference on Multimedia (ACM MM), 2023</em>
          </li>
          <li>
            <strong>Real-time semantic segmentation with parallel multiple views feature augmentation</strong><br>
            Jian-Jun Qiao, <u>Zhi-Qi Cheng</u>, Xiao Wu, Wei Li, Ji Zhang<br>
            <em>Proceedings of the 30th ACM International Conference on Multimedia (ACM MM), 2022</em>
          </li>
          <li>
            <strong>Debunking Free Fusion Myth: Online Multi-view Anomaly Detection with Disentangled Product-of-Experts Modeling</strong><br>
            Hao Wang, <u>Zhi-Qi Cheng</u>, Jingdong Sun, Xin Yang, Xiao Wu, Hongyang Chen, Yan Yang<br>
            <em>Proceedings of the 31st ACM International Conference on Multimedia (ACM MM), 2023</em>
          </li>
          <li>
            <strong>Gnas: A greedy neural architecture search method for multi-attribute learning</strong><br>
            Siyu Huang, Xi Li, <u>Zhi-Qi Cheng</u>, Zhongfei Zhang, Alexander Hauptmann<br>
            <em>Proceedings of the 26th ACM International Conference on Multimedia (ACM MM), 2018</em>
            (<font color='red'>Oral Presentation</font>)
          </li>
          <li>
            <strong>Robust Automatic Detection of Traffic Activity</strong><br>
            Alexander Hauptmann, Lijun Yu, Wenhe Liu, Yijun Qian, <u>Zhi-Qi Cheng</u>, Liangke Gui<br>
            <em>Mobility21, Carnegie Mellon University, 2023</em>
          </li>
        </ul>
        <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>
        <h4>Other Articles and Preprints:</h4>
        <ul>
          <li>
            <strong>DCPT: Darkness Clue-Prompted Tracking in Nighttime UAVs</strong><br>
            Jiawen Zhu†, Huayi Tang†, <u>Zhi-Qi Cheng</u>, Jun-Yan He, Bin Luo, Shihao Qiu, Shengming Li, Huchuan Lu<br>
            <em>arXiv preprint arXiv:2309.10491, 2023</em> 
            (Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2024)
          </li>
        </ul>
        <p>† Indicates Equal contribution by authors, ^ indicates Mentorship</p>
        </td>
        </tr>

        <hr>
      
      </tbody>
    </table>
</body>
